
$N$-Gram 방법은 많이들 아시다시피 문장을 $N$ 개의 토큰 단위로 쪼개서 그 빈도를 확인하는 방법입니다. 이 $N$-Gram 방법은 다양하게 사용데는데요. 이 방법을 Attention 개념과 연결을 시키려면 language modeling 방법에 대해서 좀 이야기를 해야 할 것 같습니다. 수많은 language modeling 방법이 있을 텐데, 통계적인 방법 중에 autoregressive modeling 방법이라는 게 있고, 저는 그것 밖에 모릅니다. 한계를 명확히 한 후에.... 설명을 드리는게 맞을 것 같아서요..

제가 알기로는 통계적 language modeling에서 하고자 하는 것은 우리가 가지고 있는, 혹은 생성한 문장이 얼마나 그럴 듯한 문장인가를 표현하는 것입니다. 이렇게 각 문장에 대한 확률을 정확히 알 수만 있으면 많은 일을 할 수 있는거죠. 만약 번역에 이 확률을 적용한다면, 번역을 하고자 하는 문장을 넣고, 그 의미를 해석한후, 해당 의미를 가지는 수많은 번역된 문장 중에, 어떤 문장이 가장 그럴듯한 문장인지를 평가해서 의미를 훼손하지 않는 가장 자연스러운 문장을 뽑아줄 수도 있을 것입니다. 

그렇게 문장의 확률을 계산해낼 수 있는 방법 중에 하나가 autoregressive sequence model입니다. autoregressive sequence model은 단어가 문장에 나타날 확률을 이전의 단어가 주어져 있을 때 얼마나 자주 나타나는가를 나타내는 조건부 확률들의 곱으로 문장의 확률을 계산합니다. 직관적으로도 상당히 호소력 있는 가정입니다. 우리는 시간이라는 제약을 받고 있는 존재이므로, 주로 사람이 말을 하거나 듣는 행위는 순차적으로 이루어 집니다. 첫번째 단어를 듣고, 그 다음 단어가 어색하지 않으면 받아들이고, 그렇지 않으면 '말이 안된다'라고 표현을 하거나, 이 것들이 계속 반복되면 결국 문장 전체를 이해할 수가 없게 되죠. 그래서 이미 듣거나 본 단어를 바탕으로 가장 그럴 듯한 다음 단어들을 선택하는 과정은 상당히 직관적으로 타당합니다. 이를 수학적으로 표면해 봐야겠습니다. 만약, 토큰, $y_1, \ldots, y_T$로 이루어진 문장 $S = (y_1, \ldots, y_T)$가 있다고 생각을 하면, 문장 $S$의 확률을 다음과 같이 분해하는 것입니다. 

$$ P(S) = P(y_1) \cdot P(y_2|y_1)\cdot P(y_3| y_2, y_1) \ldots P(y_T|y_{<T})$$

원래 문장의 확률을 구하는 문제는 unsupervised learning입니다. 이게 legitimate한 문장이다 그렇지 않다라는 label이 주어지지 않기 때문이죠. 하지만, autoregressive model은 이 unsupervised learning을 supervised learning 문제로 변환하는 역할을 합니다. 현재까지 들은 $t$개의 단어를 바탕으로 그 다음 단어의 그럴듯함을 판단하는 문제는 그 다음 단어가 나타날 확률을 추정하는 문제로 볼 수 있습니다. 이는 대표적인 supervised learning 과정입니다. 

다시 한번 요약하면, 전체 문장의 확률을 계산하는 문제를 어떤 단어들의 sequence가 주어졌을 때 새로운 단어가 나타날 확률들로 분해를 하고, 각각의 조건부 확률을 데이터로부터 구한 후에 이들을 곱하여 문장의 확률을 구하는 문제로 전환한 것입니다. 

 
하지만 문장의 모든 단어를 조건부 확률을 구하는 데 사용하는 것은 좀 문제가 있겠죠. 제일 먼저, 조건부 확률에서 condition 부분의 단어가 길어질 수록 확률 자체를 추정하기 어렵습니다. 예를 들어 직전의 단어를 보고 그 다음 단어가 나타날 확률만 구하고자 한다면, 데이터에서 쉽게 구할 수 있을 것입니다. 데이터가 얼마나 주어질 지는 모르지만, 그 숫자가 충분하다면, $A$라는 단어가 출현한 뒤에 $B$라는 단어가 출현하는 빈도수는 그렇게 적지 않을 것입니다. 당장 이 글에서 살펴 봐도 "문장의 확률을"이라는 구절은 몇번 보이는군요. 다시 말하면, 경헙적(empirical)으로 확률을 구하기가 용이하다는 것이죠. "문장의"라는 어절을 보고나서 "확률을"이라는 어절이 나올 확률을 계산해 볼 수 있겠습니다 "문장의"라는 어절이 나온 후에 따라나오는 케이스 중에서 "확률을"이라는 어절이 나온 빈도수를 세어보면 됩니다. 하지만, "문장의 확률을 계산해낼 수 있는 방법 중"이라는 구절은 딱 1번 밖에 나오지 않습니다. 그러니 빈도에 기대어서는 "문장의 확률을 계산해낼 수 있는 방법"까지라는 구절이 주어진 상태에서 "중"이라는 단어가 나올 확률은 1이고, 그렇지 않은 단어가 나올 확률은 0이 되는거죠. 아무런 정보를 뽑아낼 수 없는 상태인 것입니다.

그래서 그 차선책으로 출현 확률을 구하고자 할 때 그 단어보다 먼저 나온 $N$개의 단어만 실제로 이용하는 방법을 취할 수 있습니다. 물론, 모든 이전에 나온 단어를 사용했을 때 더 정확하게 모델링은 되겠죠. 하지만 훨씬 현실적인 접근 방법일 것 같습니다. 이렇게 이전에 출현한 $N$개의 단어들을 바탕으로 다음 단어가 나올 확률을 다음과 같이 쓰고 $N$-Gram 확률이라고 부릅니다.


$$P(y| y_{-N}, y_{-N + 1}, \ldots, y_{-1})$$


실제 데이터로부터 $N$-Gram 확률을 구하는 방법은 실제 빈도를 count하는 방법입니다. 다음과 같이 구할 수 있을 것입니다.


$$Eqn$$

