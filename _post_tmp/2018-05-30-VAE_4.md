---
layout: post
title: 'Variational Autoencoder (IV)'
author: kion.kim
date: 2018-05-30 17:00
tags: [deeplearning, statistics, generative-model]
---

## Variationa Inference 요약

VAE는 자주 GAN(Generative Adversarial Network)과 비교되는데 이는 둘 다 비지도 학습(unsupervised learning)이면서, 주어진 정보를 이용해서 무언가 새롭게 만들어낼 수 있는 능력 때문입니다. GAN이 two-player 개념에 근거하여 새로운 Loss function을 제시하였다면, VAE는 새로운 Loss Function을 제공했다기 보다는 VAE의 목적함수를 Autoencoder 개념 하에서 재해석하였다고 할 수 있습니다. VAE의 핵심은 VI입니다. 신경망은 알고리즘의 해상도를 끌어올리기 위한 트릭에 불과하다고 해도 과언이 아닙니다.

참고로 VI는 동일한 아이디어에 근거하고 있는 EM 알고리즘에 비해 확률모형에 기반하지 않고 함수를 근사하는 용도로 사용합니다. 그러므로, 사전 확률분포를 유연하게 선택할 수 있습니다. 보통은 sampling을 하기 좋은 함수를 선택합니다.

DNN을 이용함으로써, SGD 최적화 알고리즘 사용하여 쉽게 학습 가능하다. VI는 최대화시키고자 하는 목적함수에 기대값을 포함하고 있으므로, 이 기대값을 잘 추정하기 위해서는 계산량이 많은 MCMC 등의 방법론을 사용하였지만, VAE의 경우는 backpropagation을 사용해서 속도면에서 많은 개선이 있었습니다.

VAE로부터 도출한 잠재변수의 공간에서 거리는 데이터 간의 유사도를 나타냅니다. 이런 성질은 embedding의 개념과도 연결이 될 수 있습니다. 또한, 이러한 성질로 인해 원하는 데이터를 생성해낼 수 있습니다. GAN은 encoding 단계가 없기 때문에 이미지를 복원할 수 있는 능력은 없습니다. 단지 원 데이터의 분포를 찾아내기만 할 뿐, 잠재변수의 확률분포가 어떤 의미를 지니는지는 파악하기가 어렵습니다. 대신 해당 분포로 데이터를 선택해서, generator 신경망을 태운 결과를 봐야 어떤 이미지가 생성될지를 알 수 있는 반면, VAE는 잠재 공간에 어떤 데이터들이 대입되는지 알 수 있으므로 잠재공간에 대해서 좀더 많이 알 수 있는 여지는 있습니다.
