# Variational Auto Encoder

VAE는 데이터의 분포를 추정하기 위한 모형입니다. VAE는 DNN의 높은 해상력을 바탕으로 variational inference(VI) 알고리즘을 활용하여, $P(X)$를 추정합니다. 여기에서 $P(X)$는 데이터의 분포를 의미합니다. 우리가 일상에서 얻는 데이터는 차원이 큰 것이 대부분입니다. 사진, 음성 등 우리가 일상적으로 접하는 멀티미디어 데이터가 아주 좋은 예일 것입니다. 사진은 pixel 갯수만큼의 차원의 데이터이며, pixel 수는 보통 1000개는 훌쩍 넘는 크기입니다. 음성도 일초에 수만번씩 샘플링되는 아주 차원이 큰 데이터입니다. 이와 같이 데이터의 분포는 보통 아주 큰 차원에서 정의되는 확률분포로서 이 분포를 추정하는 것은 아주 어려운 일입니다. 만약 데이터를 생성하는 분포를 추정할 수 있다면, 데이터의 생성 매커니즘에 대해 좀더 깊이 이해할 수 있고, 추정된 분포를 통해 새로운 데이터를 생성(generate)해 낼 수 있습니다. 그러므로 VAE는 생성모형(generative model)의 범주에 드는 모형입니다.

강아지 그림이 있습니다. 세상에는 아주 많은 종류의 강아지가 있습니다. 그리고 그 사진 안에는 수없이 많은 각도와 pose에서 찍은 강아지들이 있습니다. 이런 수많은 강아지 이미지들은 우리가 보기에는 아주 복잡해 보이지만, 같은 사이즈의 이미지들이 표현할 수 있는 아주 많은 예중에 극히 일부에 불과합니다.

### VAE 모형

#### Manifold hypothesis

보통 우리가 보는 데이터는 사실 수학적으로 보면 아주 작은 공간에 몰려 있다고 볼 수 있습니다. $28 \times 28$ 차원짜리 MNIST 손글씨 이미지만 하더라도, 784차원의 데이터이고, 이 784차원의 데이터가 표현할 수 있는 흑백 이미지는 $255^{784}$개에 이릅니다만, 실제 숫자라는 의미를 지닌 이미지의 가짓수는 그렇게 많지는 않을 것입니다. 그러므로, 아무리 복잡해 보이는 데이터라도 그 구조만 확실하게 존재한다고 하면, 아주 작은 차원의 데이터로 표현할 수 있다고 하는 것인 deep learning에서 이야기하는 manifold hypothesis입니다.

![manifold](/assets/manifold.png)
> A Global Geometric Framework for Nonlinear Dimensionality Reduction
Joshua B. Tenenbaum, Vin de Silva, John C. Langford


위의 그림은 manifold의 개념을 가장 잘 설명해주는 그림 중의 하나입니다. 우리가 익숙한 3차원 공간에 데이터가 swiss roll 형태로 모여 있다고 하죠. 단순히 두 점의 거리를 Euclidean distance로 재면 그림 A의 점선으로 표시할 수 있습니다. 하지만, 데이터를 가장 잘 설명하는 2차원 manifold를 찾으면, 그림 B에서 보이는 것처럼 데이터를 그 manifold 위에서 설명할 수 있습니다. 이 manifold를 펴면, 그리고 그 위에서 정의된 euclidean distance는 그림 C의 녹색선으로 표시할 수 있습니다. 데이터 공간에서의 거리보다 manifold 위에서의 거리가 훨씬 크다는 것을 알 수 있습니다. 언뜻 비슷해 보이는 그림이라도 실제 공간에서는 아주 다른 그림일 수 있는 것입니다. 만약 동물의 이미지를 제대로 표현할 수 있는 manifold라면, 강아지 이미지들과의 거리가 사진에 찍히기를 언뜻 강아지 같아 보이는 고양이의 그림과의 거리는 훨씬 짧다는 것이죠.

위의 경우에서처럼, 경우에 따라서는 원래 데이터의 공간은 큰 의미가 없을 수도 있습니다. 이런 경우 neighborhood의 관측치에 기반한 kernel based 방법은 그다지 성능이 좋지 않을 수 있습니다. 그림 A에서 보는 것처럼 원래 공간에서의 neighborhood는 크게 의미가 없을 수도 있으니까요. VAE는 이런 manifold를 잘 찾아보겠다는 시도도 포함하고 있습니다.

#### VAE의 목적

데이터의 분포를 추정함에 있어, VAE의 목표는 두가지라고 할 수 있습니다. 하나는 아주 큰 차원에 존재하는 데이터의 차원을 효과적으로 줄이는 것입니다. 위에서 살펴본 manifold hypothesis에 기대어 VAE에서는 큰 차원의 데이터를 낮은 차원에서 데이터를 표현하고자 합니다. 이렇게 하면 보다 작은 차원에 존재하는 분포만 고려하면되기 때문에 계산도 훨씬 간단해 지는 효과도 있습니다.

다른 하나는, 원래 데이터의 분포의 구조를 유지하는 것입니다. 예를 들면, 784차원의 MNIST 데이터를 2차원으로 줄인다고 할 때, 784차원의 원래 이미지가 가지는 유사도를 그대로 2차원에서도 표현하고 싶은 것입니다. 숫자 '1'도 쓰는 사람의 필체에 따라 수많은 형태가 나올 텐데, 그래도 사람이 숫자 2와는 쉽게 구분할 수 있는 것을 보면, 다양한 모양의 '1'이라는 숫자는 숫자 '2'보다는 더 가까워야 할 것입니다.

이런 두가지 목적을 달성하기 위해서 VAE는 잠재변수 $Z$를 도입합니다. 이 잠재변수는 몇 개의 모수로 결정이 되는 샘플 추출이 용이한 확률변수입니다. 관측된 데이터를 확률변수 $X$라고 나타낼 때, 이 확률변수는 원래 데이터가 가지는 $D$ 차원보다는 훨씬 작은 $K$ 차원을 가집니다. 수학적으로는 $ X\in \mathbb R^D, Z\in \mathbb R^K$라고 표현합니다.

우리는 이 확률변수의 공간에서 데이터의 확률분포를 표현하기를 원합니다. 하지만, 이 두 분포는 어떤 식으로든 연결이 되어야 합니다. 그래서 우리는 데이터의 확률분포 $X$가 $x$로 주어졌다면, 그 점에 대응하는 값이 확률변수 $Z$가 이루는 공간의 어느 원소, $z$에 해당하는지를 알고 싶습니다. 이런 상황을 수학적으로 나타내면, 결국 우리가 찾고자 하는 것은 $P(Z\vert X)$입니다. Bayesian notation에 빗대면, $P(Z)$는 사전 확률분포 (prior distribution)으로, $P(Z\vert X)$는 사후분포 (posterior distribution)라고 표시할 수 있습니다.

>NOTE: Notation에 대해서 설명합니다. 확률변수는 $X$와 $Z$와 같이 대문자로 나타내고, 확률변수의 실현값은 $x$, $z$와 같이 소문자로 나타냅니다. 대문자 $P$와 $Q$는 확률 분포를 나타내고, $p$와 $q$는 확률분포와 대응되는 확률밀도 함수 (probability density function)를 의미합니다. 앞으로 많은 subscription이 보일텐데, 이는 확률분포와 확률밀도함수의 의미를 좀더 명확하게 해주는 의미로 사용됩니다. $P_X$라고 하면 확률변수 $X$의 확률분포를 의미합니다. $p_x$는 $X$의 확률밀도 함수를 의미하고, 조건부 확률분포를 나타내고 싶으면, $P_{X\vert Z}$라고 표현하겠습니다. Subscription도 확률변수를 의미하므로 대문자를 사용하겠습니다. 기대값은 $E$로 표시하고 마찬가지로 의미를 명확하게 하기 위해서는 아래첨자를 씁니다. 아래첨자는 모두 대문자로 표시하고, $E_{X\vert Z}$라고 하면 확률변수 $Z$가 주어졌을 때, 확률변수 $X$의 기대값이고, 이는 확률 변수 $Z$가 어떤 값이 주어지는가에 따라 달라지므로, $Z$의 함수가 됩니다.


VAE는 생성모형입니다. 따라서, 모형을 다 추정하고 난 후에는 모형을 생성할 수 있어야 합니다. 모형을 어떻게 생성할까요? VAE에서는 어떤 정해진 공간에서 숫자들을 뽑아내고, 그 숫자들을 하나의 시작점으로 이미지를 생성해 냅니다. 그럴려면, 어떤 정해진 공간이 필요하고, 그 공간의 틀을 만드는 것이 잠재변수 $Z$가 가지는 확률공간입니다. VAE에서 하는 작업은 그 틀이 최대한 데이터의 분포를 반영하도록 하는 것입니다. 만약 확률변수 $Z$가
$$Z \sim N\left(\left(\begin{array}{c} 0 \\ 0 \end{array}\right), \left(\begin{array}{cc}\sigma_1^2 & 0 \\ 0 & \sigma_2^2\end{array}\right)\right)$$

라는 2차원 정규분포를 따른다고 하면, $P(Z)$는 다음과 같은 확률분포를 가집니다.

![VAE_latent_prior](/assets/VAE_latent_prior.png)

위의 그림에서 보면 숫자 0에서 9까지에 해당하는 숫자들이 아무런 패턴 없이 뿌려져 있는 것을 확인할 수 있습니다. 사전 분포이므로, 실제 데이터와 아무런 관계가 없으니, $Z$가 정의된 2차원 공간에 임의로 흩어져 있습니다.

VAE가 하는 일은 잠재변수의 평면에 의미를 주고자 하는 시도라고 볼 수 있습니다. 아무 의미없는 random noise일 뿐인 $P(Z)$를 연결시켜, $P(Z\vert X)$를 찾되, 그 사후분포는 다음과 같은 모양을 띄기를 원합니다.

![VAE_using_MLP_posterior](/assets/VAE_using_MLP_posterior.png)

위의 그림은 Encoder 신경망을 학습시키고 난 후에 어떤 MNIST data의 숫자가 2차원 공간에 어떤 식으로 mapping되는지를 보여줍니다. 위와 같이 얻을 수만 있으면, 우리는 새로운 1을 뽑아내려면, 오른쪽 아래에 1이 모여 있는 점 부근에서 새로운 표본을 추출 후 이미지를 만들어내면 될 것입니다. 이미지를 만들어 내기 위해 신경망을 쓰고, 의미 있는 사후분포를 찾기 위해서 또 다른 신경망을 씁니다.


#### 두개의 신경망

확률변수 $X$와 $Z$는 두 개의 신경망(feedforward 신경망)로 연결이 되어 있습니다.  $X$에서 $Z$로 변환할 때에는 $D$ 차원의 원래 데이터를 입력으로 받아들여, 잠재변수의 모수를 결과물로 내는 신경망을 통해 연결이 되어 있습니다. 잠재변수의 모수라고 하면, 우리는 정규분포를 가정했으므로, 잠재변수의 평균과 분산이 되겠습니다. 분산도 서로 독립인 정규분포를 가정했으므로, 잠재변수의 차원수만큼의 모수만 출력하면 되겠습니다. 이 신경망을 encoder 신경망이라고 합니다.

![vae_structure](/assets/vae_structure.png)

반대로 $Z$에서 원래의 데이터로 복원(reconstruct)할 때에는 $K$ 차원의 잠재변수를 입력으로 받아 $D$ 차원의 데이터를 출력으로 하는 신경망을 통해 연결이 되어 있습니다. 이를 decoder 신경망이라고 합니다.

수학적으로 보다 정확하게 표현해 보겠습니다.

잠재변수의 모수의 개수를 $p$개라고 하면, encoder 신경망은 다음과 같이 표현할 수 있습니다.
$$\psi(x;\zeta):\mathbb R^D \rightarrow \mathbb R^p$$
여기서 $\zeta$는 신경망의 weight값입니다. encoder 신경망을 통해 얻은 모수를 바탕으로 잠재변수는 조건부 분포, $Q(Z\vert x)$를 따른다고 가정합니다. 이 조건부 분포는 여러가지로 가정할 수 있겠지만, 논문에서는 정규분포로 가정을 합니다. 정규분포는 평균과 분산을 모수로 가지므로, 정규분포의 경우 $\psi(x; \zeta)$는 $K$개의 평균값과 $K$개의 분산값, 합해서 $2K$개의 숫자를 출력합니다. 이 모수벡터를 $2K\times 1$ 크기의 $\phi$라고 하면,

$$\phi^T(x; \zeta) =(\mu^T(x; \zeta), \sigma^T(x; \zeta))$$

로 구성됩니다. 여기서 $\mu(x; \zeta)$와 $\sigma(x; \zeta)$는 각각 $K\times 1$ 차원의 평균과 분산 벡터입니다. 이런 상황에서, 데이터가 주어져 있는 경우 잠재변수의 조건부 분포는 다음과 같이 쓸 수 있습니다.

$$Q_\phi(Z\vert x) \sim N(\mu(x; \zeta), \sigma(x; \zeta))$$

요약하자면, 원래 데이터를 입력으로 넣으면, encoder 신경망은 잠재변수의 모수를 출력하고, 잠재변수는 이 모수를 평균과 분산으로 하는 조건부 분포를 따름을 의미합니다.

decoder 신경망은 $f(z;\theta):\mathbb R^K \rightarrow \mathbb R^D$로 변환하는 함수로 $\theta$는 신경망의 weight 값들입니다. 이러한 신경망에 근거해서 만약에 잠재변수 $Z=z$가 선택이 되면, 데이터는 $f(z;\theta)$를 중심으로 $\sigma^2 I$를 분산으로 가지는 분포를 따릅니다. 이를 수식으로는 다음과 같이 나타냅니다.

$$P(X\vert Z= z) \sim N(X\vert f(z;\theta),\sigma^2 \bm I)$$

를 따른다고 가정합니다. 여기서 $\sigma^2$는 hyper-parameter로 분석가에 의해 결정이 됩니다.


### 추정

#### 최우추정 원리

우리가 추정해야 할 모수는 $\zeta$, $\theta$입니다. 각각 encoder 신경망과 decoder 신경망의 weight 값을 의미합니다. 잠재변수의 사후분포(posterior distribution)의 모수인 $\mu$와 $\sigma$는 $\zeta$가 정해지면 같이 정해지는 숫자이며, 실제 잠재변수를 표현할 때에는 이 모수들을 이용해서 시각화 할 것입니다. $f(z;\theta)$가 결정이 되면 여기에 약간 noise를 더한 값이 생성하는 이미지가 됩니다. VAE에서 궁극적으로 하고자 하는 것은 최대 우도 원칙(Maximum Likliohood Principle)에 의거해서 데이터의 분포를 추정하는 것입니다. 다음은 우도함수(우도함수)의 정의입니다.
$$ P(X;\nu) = L(\nu; X)$$
$X$는 데이터를 의미합니다. $\nu$는 추정하고자 하는 모수(parameter)를 의미합니다. 우도함수와 확률분포 함수는 동일한 함수로, 보는 관점만 다르다고 볼 수 있습니다. 확률분포는 사상(Event)가 발생할 확률을 assign하는 원칙을 정의하는 것으로, 데이터가 나올 확률을 가장 크게 해주는 모수를 찾고자 한다면, 우도함수로 이해할 수 있습니다.

만약, 다수의 관측치가 있고, 관측치 사이에 독립성 가정이 주어졌을 경우, 다음과 같이 쓸 수 있습니다.

$$ L(\theta; X) = \prod_{i=1}^n p(x_i;\theta)$$

이 최대우도 원리는 생성 모형이 출현하면서 deep learning의 알고리즘을 이해하기 위해 필수적인 요소가 되어가고 있습니다. 인공지능의 빙하기를 깬 Restricted Boltzmann Machine에서 많이 사용된 이후, 한동안 분류 문제가 많이 대두됐던 지난 몇년 동안에는 확률분포와 MLE 원리가 그렇게 중요한 개념이 아니었습니다. 예측 성능을 높이기 위해 MSE와 categorical entropy를 줄이면 되는 상황이었습니다. 하지만, VAE와 GAN을 중심으로한 생성 모형이 중요한 연구 대상이 되면서, 데이터를 생성해 내는 분포를 추정해야 됨에 따라, 이제는 생성 모형의 알고리즘을 이해하기 위해서는 확률분포에 대한 이해가 아주 중요한 부분이 되었습니다.

이제 우리가 찾아야 하는 모수, $\zeta, \theta$의 최우추정량들을 찾아보도록 하겠습니다.

최우 추정치를 찾기 위해 VAE에서는 Variational Inference라는 방법을 사용합니다. 이름에도 나와 있습니다. 그러므로, VAE에 대해 깊이 이해하기 위해서는 Variational Inference(VI)를 제대로 이해해야 합니다. VI는 EM 알고리즘과 비슷하게 닮아 있지만, 일치하지는 않습니다. EM 알고리즘은 hidden variable과 hidden variable이 주어진 경우의 conditional distribution을 명확히 가정하여, 최종적으로는 관측된 data의 확률 성질을 알고 싶은 것이 가장 큰 목적입니다만, VI는 통계적인 분포를 추정하기 위한 방법론이라기 보다는 함수 근사(function approximation)의 도구로 주로 사용됩니다. 먼저 EM 알고리즘에 대해서 잠시 언급한 후 variational inference에 대해서 알아보도록 하겠습니다.


#### EM 알고리즘

통계학에서는 확률분포만 정확하게 알고 있으면, 주어진 data로 알아낼 수 있는 모든 현상은 계산해 낼 수 있다고 생각합니다. Frequentist, Fisherian들이 많이 연구하는 모수통계(Parametric statisics)에서는 그러한 확률분포가 몇몇 개의 모수로 표현되는 경우를 상정하고 그 가정 하에서 분포를 찾아내는 작업을, 비모수통계(Nonparametric statics)에서는 최소한의 가정만으로 이를 찾아내고자 합니다. 또 하나의 극단은, 이런 확률 분포를 sample로 가지고 있는 경우로, Bayesian들이 주로 택하는 방법입니다.

모수적인 방법은 이론적으로 아름답지만, 다룰 수 있는 문제의 범위가 작고, 비모수 통계는 모수가 엄청 많은 모수방법으로 이해할 수 있으므로, 해결할 수 있는 문제의 범위가 좀 더 넓습니다. 반면, Sampling 방법에 의존한 방법들은 computing power만 허락한다면, 거의 모든 문제를 다룰 수 있습니다.

현대의 머신러닝에서는 모수적인 방법이라고 하더라도, 우도함수가 아주 복잡한 함수일 경우가 많아, 이를 바로 추정하는 것은 계산상 거의 불가능한 일인 경우가 대부분일 것입니다. 이런 경우에 가장 쉽게 취할 수 있는 방법이 sampling하는 방법입니다만, sampling 방법은 시간이 많이 든다는 커다란 단점이 있습니다. 이런 문제를 피해가기 위해서 근사법(approximation method)를 사용하게 됩니다.

함수를 근사하는 방법에는 Laplace approximation 등의 방법이 존재하기는 하지만, 나중에 Bayesian에서 사용하는 VI와 관계된 idea로 EM 알고리즘 (Dempster et al. 1977)이 있습니다. 만약 실제 관측되는 변수의 생성원리(probabilitistic mechanism)를 잘 설명할 수 있는 잠재변수(Latent variable)을 알 수 있다면, 위의 우도함수는 다음과 같이 쓸 수 있습니다.

$$L(\theta; x)= p(x\vert \theta)=\sum_z p(x,z\vert \theta)=\int_\Omega p(x,z\vert \theta)dz$$

이런 모형이 상정하면, 위에서 정의한 $L(\theta; X)$는 관측할 수 없는 잠재변수를 적분이나 합을 통해 평균을 내버려, 우도함수에서 변수의 역할을 하지 않으므로, marginal 우도함수라고 부릅니다. $p(x, z)$를 안다는 것은 $p(x\vert z)$를 알고, $p(z)$를 안다는 것과 동치입니다. $P(x\vert z)$는 확률 모형으로 설정하여 **추정** 을 하고, $p(z)$는 보통 **가정** 을 하게 됩니다.

사실상 EM 알고리즘을 적용할 수 있는 문제가 그렇게 많지는 않습니다. EM 알고리즘을 만들 수 있으려면, 다음의 두가지가 만족이 되어야 합니다.

  * 관측되는 현상을 만들어내는 원리를 묘사할 수 있는 잠재변수(Latent variable)과 이를 연결시켜줄 수 있는 확률모형이 존재해야 한다.
  * 그러한 상황에서 Latent variable을 추정할 수 있어야 하고, 무엇보다도 문제를 간소화 할 수 있어야 한다.

EM 알고리즘을 활용하는 모형으로 가장 많이 알려진 모형은 mixture model입니다. k-means clustering 모형이 Mixture 모형의 special case라는 점에서 k-means 모형도 EM 알고리즘의 framework 하에서 설명이 가능합니다. 그 이외에 적용하는 사례는 그렇게 많이 찾아볼 수는 없습니다.

Mixture model은 관측되는 확률 분포가 간단한 확률 분포 여러개가 섞여 있는 형태로 가정합니다. 아래의 그림을 보면 mixture 모형의 구조를 직관적으로 이해하실 수 있을 것입니다.

![7 Component Gaussian Mixture](/assets/img1.png "Title")

수학적으로 Mixture 분포는 다음과 같이 정의됩니다.

$$p(x\vert \theta)=\sum_{k=1}^K \pi_k N(x\vert \mu_k,\Sigma_k), \quad \sum_{k=1}^K \pi_k=1$$

$\theta$는 여기서 $(\mu_k, \Sigma_k), k = 1, \ldots, K,$가 되고, 이는 $K$개 확률분포의 평균과 분산을 의미합니다. 위의 그림은 단변량 정규분포를 가정한 것이지만, 수식에서는 다변량 정규분포인 경우를 생각하여 표현해 놓았습니다. 이렇게 표현함으로써 위와 같은 복잡한 분포를 $K$개의 간단한 분포의 합으로 표현할 수 있습니다. 이렇게 얻은 복합 분포는 확률의 공리를 만족하는 정당한 확률분포입니다.

> Note: 정당한 확률분포는 적분값이 1이고, 모든 영역에서 비음이어야 합니다. $K$개의 확률분포의 가중평균이므로 당연히 0보다는 클 것이고, 적분 값이 1이라는 사실은 다음과 같이 간단하게 보일 수 있습니다.
$$\int f(x\vert \theta) dx =\int \sum_{k=1}^K \pi_k f_k(x\vert \mu_k,\Sigma_k) dx = \sum_{k=1}^K\int f_k(x\vert \mu_k,\Sigma_k) dx=1$$

$\pi_k$는 mixing proportion이라고 불리며, 이는 관측된 데이터가 $k$ 번째 분포에 속할 확률을 의미합니다. 사실 관측치가 $k$번째 분포에 속하는지 그렇지 않은지는 확률의 문제가 아닌 결정적인 문제입니다. $k$로부터 나온 데이터이면 1, 그렇지 않으면 0입니다. 이미 관측되었기 때문입니다. 이런 상황을 표현하기 위해 관측치가 어느 요소 분포로부터 나왔는지를 표현하는 새로운 확률변수를 다음과 같이 정의합니다.

$$
Z_{ij}  =\left\{ \begin{array}{cc} 1 & x_i \in j \\ 0 & o.w. \end{array}\right.
$$

확률변수 $Z$는 $K$개 분포에 대해 membership을 확률적으로 결정하는데 이 때, $Z$는 $K$-multinomial 분포를 따릅니다. $k$번째 요소에 1이 나올 확률은 $\pi_k$가 됩니다. 수학적으로 쓰면 다음과 같습니다.

$$
Z \sim Multi(p_1, \ldots, p_K)
$$

잼재 변수를 활용해서 우도함수를 다음과 같이 쓸 수 있습니다.

$$
L(\eta; x_{i=1}^N) = p(x_1,\ldots, x_n \vert \eta) =\prod_{i=1}^N \prod_{j =1 }^K p(x_i\vert j,\eta)^{z_{ij}}
$$

하지만 실제 관측된 데이터는 $Z$에 해당하는 부분이 없습니다. 그래서 통계학 문제에서는 missing information 문제로 여기기도 합니다. 이렇게 불완전한 정보를 활용해서 우도함수를 극대화시키는 데에 EM 알고리즘을 활용합니다.

간단히 말해, EM 알고리즘은 잠재변수의 도입으로 쉽게 계산할 수 있는 하한(lower-bound)를 계산하고, 이 하한을 최대화하는 모수를 찾는 과정을 반복하는 것입니다. 실제로 계산이 어려운 잠재변수와 관찰변수가 모두 포함되어 있는 우도함수 대신 잠재변수가 제거된 계산이 용이하고 최대화시키기 수월한 함수를 사용합니다. 매 단계에서 그러한 함수를 찾아가는 과정을 **Expectation step** 이라고 하고 그렇게 얻은 함수를 최대화하는 과정을 **Maximization step** 이라고 합니다. 다음의 그림에서 그 아이디어를 확인하실 수 있습니다.

![](/assets/img2.png "Title")

한가지 더 언급할 것은 우도함수 대신에 로그 우도함수를 최대화할 것이라는 점입니다. 우도함수 자체는 확률밀도 함수를 계속 곱하는 형태이므로 아주 작은 값이 되는 경우가 아주 많습니다. 이런 경우 쉽게 under-flow가 발생을 하게 되죠. 그리고 계산과정에서 곱하기를 계속 달고 다녀야 하므로, 식을 전개하기가 어렵습니다. 로그 변환 자체는 단조 증가 변환이므로 로그 우도함수를 최대화 한다는 것과 우도함수를 최대화 한다는 것은 동치입니다.


수많은 하한이 있을 수 있습니다. 심하게 말하면 모든 함수값, $f(x), x \in \mathcal X$에서 1을 뺀 함수, $f(x)-1$,도 당연히 하한입니다. 하지만, 하한이 원래 함수를 잘 근사하지 못하거나, 원래 함수보다 하한 함수의 계산이 쉬워진다는 등의 이득이 없다면 그냥 의미 없는 수많은 하한 중의 하나일 뿐입니다. 지금부터는 우도함수보다 항상 작은 **의미있는** 하한을 찾아 보도록 하겠습니다.

어떤 확률분포 $Q$을 따르는 확률변수 $z$가 있다고 합시다. EM 알고리즘에서는 확률 분포, $Z$,는 당연히 확률적으로 $X$를 생성하는데 통계적으로 의미를 지니는 함수입니다. 우리에게 $n$개의 관찰점, $x_i, i =1, \ldots, n$,이 있다고 하면, 다음과 같이 로그 우도함수를 적을 수 있습니다. 참고로, 대문자 $X$는 확률변수를 의미하고 소문자 $x$는 실제 관측치를 의미합니다. 잠재변수의 경우, $z$는 관측이 되지는 않지만, 잠재변수의 실현값이라고 생각할 수 있습니다.

$$l(\theta) = \sum_{i = 1 } ^n \log \sum_{z} Q(z) \left[\frac{p_\theta( x_i, z ;\theta)}{Q(z)}\right]
  = \sum_{i=1}^n \log E_{Z\sim Q}\left[\frac{p( x_i, Z ;\theta)}{Q(Z)}\right]
  \ge \sum_{i=1}^n E_{Z\sim Q}\left[\log\frac{p( x_i, Z ;\theta)}{Q(Z)}\right]
$$

위의 식에서 가장 마지막 부등식은 Jensen inequality에 의해 성립합니다.

> NOTE 1: 일단, $Z$는 finite support를 가지는 이산 확률분포라고 가정을 하면, 기대값을 합으로 표현할 수 있습니다.
> NOTE 2: 기대값 연산자의 아래첨자는 기대값을 구하는 대상 분포를 의미합니다. 가장 오른쪽 항의 기대값은 Q라는 확률분포를 따르는 확률변수 $Z$의 함수에 대한 기대값이라는 것을 뜻합니다.



로그 우도함수와 가장 비슷한 lower bound를 생각해 보면, 결국 다음이 성립하는 분포를 $Q$로 정할 때일 것입니다.

$$l(\theta) = \sum_{i=1}^n E_{Z\sim Q}\left[\log\frac{p( x_i, Z ;\theta)}{Q(z)}\right]$$

당연히 우리는 한번만에 로그 우도함수의 최대치를 찾을 수 없으므로, 반복적으로 우도함수의 최대값을 탐색해 나갈 것이고, 그 과정에서 하한을 개선시켜 나갈 것입니다. 다시 말하면, $t$ 번째 반복에서 하한을 찾아내어 최대화시킨 후, $t+1$번째 반복에서 다시 새로운 하한을 찾은 후에 최대화시키는 과정을 수렴 시점까지 계속 반복해야 합니다. 이렇게 $t$번 반복해서 얻은 $\theta^{(t)}$를 바탕으로 $\theta^{(t+1)}$을 찾는 상황으로 좁혀 보면, $Q^{(t+1)}$를 효율적으로 잘 찾아야 $\theta^{(t+1)}$을 잘 찾을 수 있을 것입니다. $t$-번째 반복이 이루어진 상황에서, 위의 Jensen's inequality에서 등호가 성립하려면, $\log\frac{p( x_i, z ;\theta^{(t)})}{Q^{(t+1)}(z)}$가 상수여야 합니다. 이는 곧 $\frac{p( x_i, z ;\theta^{(t)})}{Q^{(t+1)}(z)}$가 상수여야 함을 의미합니다. 이런 사실은 $Q^{(t+1)}(z)$이 $p( x_i, z ;\theta^{(t)})$에 비례해야 한다는 것을 의미하고, $Q^{(t)}(z)$가 $z$에 관한 함수이므로, 다음의 관계를 도출할 수 있습니다.

$$Q^{(t+1)}(z) = \frac{p( x_i, z ;\theta^{(t)})}{\sum_z p( x_i, z ;\theta^{(t)})} = p( z \vert  x_i, \theta^{(t)})$$

> NOTE: $\sum_z p( x^{(i)}, z ;\theta^{(t)})$는 $z$에 관해 상수입니다.

이는, $t$ 번째 반복에서 얻어진 모수, $\theta^{(t)}$,가 주어진 상태에서의 확률변수, $Z$,의 posterior 분포가 가장 효율적인 $Q^{(t+1)}$의 역할을 할 수 있음을 의미합니다. 지금까지의 논의를 바탕으로 $\theta^{(t+1)}$은 다음의 update rule을 가집니다.

$$\theta^{(t+1)} = \arg\max_{\theta} \sum_{i = 1}^ n E_{Z\sim Q^{(t+1)}}\left[\frac{p( x_i, Z ;\theta^{(t)})}{Q^{(t+1)}(Z)}\right]$$


한가지 더 확인해야 할 것은 $(t+1)$ 번째 반복에서 얻어진 log-우도함수의 값이 $t$ 번째 얻어진 log-우도함수의 값보다 항상 커지는가하는 것이고, 수식으로 나타내면, $l(\theta^{(t+1)}) \ge l(\theta^{(t)})$임을 보이는 것으로, 이 관계가 성립됨을 다음의 식에서 알 수 있습니다.

**************** Monotonicity 추가

#### Variational Inference 알고리즘

최대화하기 어려운 marginal 우도함수 대신에 최대하기 쉬운 우도함수의 lower bound를 찾아내서, 이를 극대화하고자 하는 것이 EM 알고리즘의 key idea입니다. 이를 위해 EM 알고리즘에서는 data 생성 과정을 모델링하지만, VI는 하한을 극대화한다는 아이디어만 차용합니다. 다음과 같이 marginal 우도함수를 분해할 수 있습니다.

$$p(x) = \sum_z p(x, z) = \sum_z q (z\vert x) \frac{p (x,z)}{q(z\vert x)} = E_{Q(Z\vert x)}\left[\frac {p (x, Z)}{q(Z\vert x)}\right]$$

두 개의 서로 다른 parameter set, ($\phi, \theta$)를 가지고 있는 경우에 이를 적용하면 다음과 같은 결과를 얻을 수 있습니다.

$$\log p(x) = \log E_{Q_\phi (Z\vert x)}\left[\frac {p (x, Z)}{q(Z\vert x)}\right]\ge E_{Q (Z\vert x)}\left[\log\frac {p (x, Z)}{q(Z\vert x)}\right]$$

오른쪽의 식이 KL divergence와 일치하는군요.

KL divergence의 정의로부터, 먼저 marginal 우도함수를 뽑아내면, 맨 아래처럼 두개의 요소로 분리할 수 있습니다.

$$\begin{array}{ll}
D_{KL}( Q_\phi(Z\vert x) \vert \vert  P_\theta(Z\vert x)) &= \sum_z \log  \frac{q_\phi(z\vert x)}{p_\theta(z\vert x)} q_\phi(z\vert x)\\
&= \int \log \frac{q_\phi(z\vert x)p(x)}{p_\theta(z,x)} q_\phi(z\vert x)dz\\
&= \int \log \frac{q_\phi(z\vert x)}{p_\theta(z,x)} q_\phi(z\vert x)dz + \log p_\theta(x)\underbrace{\sum_z q_\phi(z,x)}_{1}\\
&= \log p_\theta(x) + \underbrace{E_{q_\phi (z\vert x)}[\log q_\phi(z\vert x)] - E_{q_\phi (z\vert x)}[\log p_\theta(z,x)]}_{\mathcal L(\theta, \phi; x)}
\end{array}$$

$\mathcal L(\theta, \phi; x)$을 왼쪽으로 넘기면,
$$\begin{array}{ll}
\log p_\theta(x) &=  - E_{Q_\phi (Z\vert x)}[\log q_\phi(Z\vert x)] + E_{Q_\phi (Z\vert x)}[\log p_\theta(Z,x)] + D_{KL}( Q_\phi(Z\vert x) \vert \vert P_\theta (Z\vert x))\\
& \ge \underbrace{- E_{Q_\phi (Z\vert x)}[\log q_\phi(Z\vert x)] + E_{Q_\phi (Z\vert x)}[\log p_\theta(Z,x)]}_{ELBO}
\end{array}$$

이라는 결과를 얻는데, 우리는 마지막 줄의 결과물을 ELBO(Evidence Lower BOund)라고 부릅니다.  KL divergence는 항상 0보다 크거나 같은 값을 가지므로, ELBO는 언제나 주변(marginal) 우도함수보다 작습니다. ELBO는 우도함수와 KL divergence와의 gap을 의미하기도 합니다. ELBO는 잠재 확률변수의 기대값으로 표현을 할 수 있고, 잠재 변수는 상대적으로 작은 차원을 가지고 있으므로, 주변 우도함수 대신 ELBO를 극대화하는 전략을 취하는 것이 계산상 유리합니다.


#### Variational Inference와 AutoEncoder

이제부터 이 VI가 어떻게 Autoencoder와 연결이 되는지에 대해서 알아보도록 하겠습니다. ELBO는 다음과 같이 다시 쓸 수 있다.
$$\begin{array}{ll}
-E_{Q_\theta (Z\vert x)}[\log q_\phi(Z\vert x)] + E_{Q_\theta (Z\vert x)}[\log p_\theta(z,x) &= -\sum_z \log q_\phi(z\vert x) q_\phi (z\vert x) +
\sum_z \log p_\theta (z,x) q_\phi (z\vert x)\\
&= \sum_z \left\{-\log q_\phi(z\vert x) + \log p_\theta(z,x)\right\} q_\phi (z\vert x)\\
&= \sum_z \left(\log p_\theta(x\vert z) -\log \frac{q_\phi(z\vert x)}{p(z)} \right) q_\phi (z\vert x)\\
&= \underbrace{-D_{KL}(Q_\phi(Z\vert x)\vert \vert P(Z))}_{(1)} + \underbrace{E_{Q_\phi(Z\vert x)} \log p_\theta(x\vert Z)}_{(2)}
\end{array}$$

마지막 줄에 VAE의 목적함수가 나타나 있습니다. 이 목적함수를 해석하자면, (1)번 부분은 Latent space에서 확률변수 $Z$의 사전분포와 데이터 포인트 $x$가 주어진 조건 하에 mapping된 확률변수 $Q(Z\vert x)$의 KL divergence이며, 그 두 분포의 차이를 줄이는 방향으로 학습을 합니다. (2)번 부분은 주어진 잠재변수의 실현값, $z$로부터 encoder 신경망에 의해서 생성된 이미지의 로그 우도함수를 크게 하는 방향으로 학습을 합니다.

실제 (1)번 항에 해당하는 실제 목적함수는 어떻게 구할 수 있을까요? 위에서도 언급했지만, 논문에서는 $N(0, \bm I)$라는 사전분포를 가정합니다. 위의 notation에서는 $P(Z)$입니다. 이에 대해 사후 확률분포는 다음과 같이 가정하였습니다.

$$Q_\phi(Z\vert x) \sim N(\mu_x, \Sigma_x)$$

위의 표현에서 $\mu_x$와 $\Sigma_x$는 모두 원래의 데이터 $x$를 입력값으로 받는 신경망에 의해 결정됩니다. 이렇게 가정하면 (1)번 항은 결국 $D_{KL}(N(\mu_x, \Sigma_x) \vert \vert  N(\bm 0, \bm I))$가 됩니다. 두 분포 모두 차원은 같습니다.

$$
D_{KL}(Q_\phi(Z\vert x)\vert \vert P(Z)) = D_{KL}(N(\mu_x, \Sigma_x) \vert \vert  N(\bm 0, \bm I)) = \frac 1 2 \left\{tr(\Sigma_x) + \mu_x\Sigma_x^{-1}\mu_x - K - \log(\vert \Sigma_x\vert )\right\}
$$

두번 째 항은 원래 데이터와 잠재변수로부터 decoder를 거쳐 생성된 데이터를 비교합니다. 이 부분을 reconstruction 부분이라고 하는데요, 실제 공간에서도 좋은 성능을 발휘할 수 있도록 하는 역할을 합니다.

두번 째 항에는 두가지 문제점이 있습니다. 첫번째 이유는 두번째 항은 $X =x$일 때, 잠재 확률변수 $Z$의 조건부 기대값을 포함하고 있습니다. 잠재변수 공간이 원래 데이터 공간보다 훨씬 작은 공간이기는 하지만, 기대값을 구하기 위해서는 여전히 상당히 많은 수의 잠재변수의 샘플이 필요합니다. 기대값의 추정에 있어서는 1개의 표본이 그 기대값을 대표한다고 생각합니다. 사실 데이터가 1개 밖에 없을 경우, 그 데이터가 바로 가장 좋은 기대값의 추정치가 됩니다. 이런 논리로, 샘플보통 한 배치를 학습할 때 여러개의 데이터가 들어가므로, 그 데이터의 복원된 이미지를 평균을 내면, 이 평균이 두번째 항에 있는 기대값을 잘 추정해주기를 바라면서 해결합니다.

더 큰 문제는 back propagation 과정에서 발생합니다. 이 문제는 reparameterization trick으로 해결할 수 있습니다.

#### Repameterization trick

![vae_reprametrization_trick](/assets/vae_reprametrization_trick.png)


VAE는 거의 최초로 reconstruction이라는 개념을 소개한 방법론입니다. 이후 잇따라 개발된 GAN 모형들과 여러가지 vision 관련된 모형들은 reconstruction이라는 개념을 사용합니다.


## VAE의 단점



## Variationa Inference 요약

VAE는 자주 GAN(Generative Adversarial Network)과 비교되는데 이는 둘 다 비지도 학습(unsupervised learning)이면서, 주어진 정보를 이용해서 무언가 새롭게 만들어낼 수 있는 능력 때문입니다. GAN이 two-player 개념에 근거하여 새로운 Loss function을 제시하였다면, VAE는 새로운 Loss Function을 제공했다기 보다는 VAE의 목적함수를 Autoencoder 개념 하에서 재해석하였다고 할 수 있습니다. VAE의 핵심은 VI입니다. 신경망은 알고리즘의 해상도를 끌어올리기 위한 트릭에 불과하다고 해도 과언이 아닙니다.

참고로 VI는 동일한 아이디어에 근거하고 있는 EM 알고리즘에 비해 확률모형에 기반하지 않고 함수를 근사하는 용도로 사용합니다. 그러므로, 사전 확률분포를 유연하게 선택할 수 있습니다. 보통은 sampling을 하기 좋은 함수를 선택합니다.

DNN을 이용함으로써, SGD 최적화 알고리즘 사용하여 쉽게 학습 가능하다. VI는 최대화시키고자 하는 목적함수에 기대값을 포함하고 있으므로, 이 기대값을 잘 추정하기 위해서는 계산량이 많은 MCMC 등의 방법론을 사용하였지만, VAE의 경우는 backpropagation을 사용해서 속도면에서 많은 개선이 있었습니다.

VAE로부터 도출한 잠재변수의 공간에서 거리는 데이터 간의 유사도를 나타냅니다. 이런 성질은 embedding의 개념과도 연결이 될 수 있습니다. 또한, 이러한 성질로 인해 원하는 데이터를 생성해낼 수 있습니다. GAN은 encoding 단계가 없기 때문에 이미지를 복원할 수 있는 능력은 없습니다. 단지 원 데이터의 분포를 찾아내기만 할 뿐, 잠재변수의 확률분포가 어떤 의미를 지니는지는 파악하기가 어렵습니다. 대신 해당 분포로 데이터를 선택해서, generator 신경망을 태운 결과를 봐야 어떤 이미지가 생성될지를 알 수 있는 반면, VAE는 잠재 공간에 어떤 데이터들이 대입되는지 알 수 있으므로 잠재공간에 대해서 좀더 많이 알 수 있는 여지는 있습니다.


## VAE의 구현
